{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4653c0f1-518b-4bc9-8325-7d1495796249",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'AE'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAE\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mAE\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Autoencoder, GeneExpressionDataset\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'AE'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import yaml\n",
    "from AE.AE import Autoencoder, GeneExpressionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "edc396af-6576-4a98-987b-9fbd45a5f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/training_data.pkl','rb') as f:\n",
    "    data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "139914e4-3750-496b-9b53-51dd74c881b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = data['X_train_tensor']\n",
    "X_val_tensor = data['X_val_tensor']\n",
    "input_dim = data['input_dim']\n",
    "loader_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "049b8dbe-de52-4e48-8533-578fea3800c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4287ae67-b551-4f4a-ad8e-75d584ae47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('optuna_parameter.yaml', \"r\") as f:\n",
    "    optuna_parameters=yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a982531-132e-4064-b0a1-4150231ce456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [64, 128, 256],\n",
       " 'dropout_rate': [0, 0.5],\n",
       " 'n_hidden_layers': [1, 3],\n",
       " 'latent_dim': [16, 256],\n",
       " 'lr': [1e-05, 0.001]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a32e42d8-9663-4f94-a543-45a88bf618c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial, optuna_parameters, input_dim, loader_workers):\n",
    "    # --- Hyperparameter Suggestions ---\n",
    "    latent_dim = trial.suggest_int(\"latent_dim\", *optuna_parameters[\"latent_dim\"]) # Range for latent space size\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", *optuna_parameters[\"dropout_rate\"]) # Range for dropout\n",
    "    lr = trial.suggest_float('lr',*optuna_parameters[\"lr\"]) # Learning rate\n",
    "    batch_size = trial.suggest_categorical('batch_size',optuna_parameters[\"batch_size\"]) # Batch size options\n",
    "    n_hidden_layers = trial.suggest_int('n_hidden_layers',*optuna_parameters[\"n_hidden_layers\"]) # Number hidden layers\n",
    "\n",
    "    # Define hidden dimensions proportional to the previous layer\n",
    "    hidden_dims = []\n",
    "    current_dim_upper_bound = input_dim\n",
    "    current_dim_lower_bound = latent_dim\n",
    "\n",
    "    for i in range(n_hidden_layers):\n",
    "         # Suggest dimensions between the current upper bound and latent_dim+buffer\n",
    "         # relative to previous/next layer.\n",
    "        if i == 0: # First hidden layer\n",
    "             dim = trial.suggest_int(f'h_dim_{i}', int(latent_dim * 1.5), int(input_dim * 0.8))\n",
    "        else: # Subsequent hidden layers\n",
    "             # Ensure next layer is smaller than previous\n",
    "             # Use the size of the previously suggested layer\n",
    "             prev_dim = hidden_dims[-1]\n",
    "             dim = trial.suggest_int(f'h_dim_{i}', int(latent_dim * 1.1), int(prev_dim * 0.9))\n",
    "        hidden_dims.append(dim)\n",
    "\n",
    "    # --- Model Training ---\n",
    "    model = Autoencoder(input_dim, latent_dim, hidden_dims, dropout_rate).to(device)\n",
    "    criterion = nn.MSELoss() # Mean Squared Error Loss for reconstruction\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # Adam optimizer\n",
    "\n",
    "    # Data Loaders\n",
    "    train_dataset = GeneExpressionDataset(X_train_tensor)\n",
    "    val_dataset = GeneExpressionDataset(X_val_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=loader_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=loader_workers)\n",
    "\n",
    "    # Training loop \n",
    "    N_EPOCHS = 20 # Few epochs to evaluate performances\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_x, _ = model(batch)\n",
    "            loss = criterion(recon_x, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                recon_x, _ = model(batch)\n",
    "                loss = criterion(recon_x, batch)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        # --- Optuna Pruning ---\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Return the final validation loss\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff7c78ca-3952-473d-93cd-7c7055a43628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 11:26:41,785] A new study created in memory with name: no-name-c30bfb47-6a36-4a4b-b157-d6320591b97c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optuna optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 11:27:12,346] Trial 0 finished with value: 0.6637172698974609 and parameters: {'latent_dim': 56, 'dropout_rate': 0.1123616935705582, 'lr': 0.00047764012193674823, 'batch_size': 256, 'n_hidden_layers': 1, 'h_dim_0': 936}. Best is trial 0 with value: 0.6637172698974609.\n",
      "[I 2025-07-02 11:27:50,814] Trial 1 finished with value: 0.7155625522136688 and parameters: {'latent_dim': 83, 'dropout_rate': 0.07752974170260729, 'lr': 0.0009588025729706499, 'batch_size': 256, 'n_hidden_layers': 2, 'h_dim_0': 1453, 'h_dim_1': 362}. Best is trial 0 with value: 0.6637172698974609.\n",
      "[I 2025-07-02 11:28:23,638] Trial 2 finished with value: 0.8383306860923767 and parameters: {'latent_dim': 59, 'dropout_rate': 0.4189875618161529, 'lr': 0.0005076863741872525, 'batch_size': 128, 'n_hidden_layers': 3, 'h_dim_0': 961, 'h_dim_1': 152, 'h_dim_2': 98}. Best is trial 0 with value: 0.6637172698974609.\n",
      "[I 2025-07-02 11:29:02,508] Trial 3 finished with value: 0.6724217534065247 and parameters: {'latent_dim': 202, 'dropout_rate': 0.013132583546501986, 'lr': 0.0007005574891036441, 'batch_size': 64, 'n_hidden_layers': 1, 'h_dim_0': 801}. Best is trial 0 with value: 0.6637172698974609.\n",
      "[I 2025-07-02 11:29:54,880] Trial 4 finished with value: 0.7145291641354561 and parameters: {'latent_dim': 102, 'dropout_rate': 0.08900822427986, 'lr': 0.0009486032368318931, 'batch_size': 64, 'n_hidden_layers': 1, 'h_dim_0': 1028}. Best is trial 0 with value: 0.6637172698974609.\n",
      "[I 2025-07-02 11:29:58,869] Trial 5 pruned. \n",
      "[I 2025-07-02 11:30:19,351] Trial 6 pruned. \n",
      "[I 2025-07-02 11:31:20,631] Trial 7 finished with value: 0.6441430374979973 and parameters: {'latent_dim': 146, 'dropout_rate': 0.2590700565837698, 'lr': 0.0002251207702163308, 'batch_size': 64, 'n_hidden_layers': 1, 'h_dim_0': 1424}. Best is trial 7 with value: 0.6441430374979973.\n",
      "[I 2025-07-02 11:31:26,632] Trial 8 pruned. \n",
      "[I 2025-07-02 11:31:36,802] Trial 9 pruned. \n",
      "[I 2025-07-02 11:31:42,862] Trial 10 pruned. \n",
      "[I 2025-07-02 11:31:43,990] Trial 11 pruned. \n",
      "[I 2025-07-02 11:31:44,737] Trial 12 pruned. \n",
      "[I 2025-07-02 11:31:45,294] Trial 13 pruned. \n",
      "[I 2025-07-02 11:32:49,560] Trial 14 finished with value: 0.647002100944519 and parameters: {'latent_dim': 123, 'dropout_rate': 0.1829484692649964, 'lr': 0.0003696182740832468, 'batch_size': 128, 'n_hidden_layers': 1, 'h_dim_0': 2035}. Best is trial 7 with value: 0.6441430374979973.\n",
      "[I 2025-07-02 11:32:55,771] Trial 15 pruned. \n",
      "[I 2025-07-02 11:32:58,757] Trial 16 pruned. \n",
      "[I 2025-07-02 11:33:05,879] Trial 17 pruned. \n",
      "[I 2025-07-02 11:33:52,805] Trial 18 pruned. \n",
      "[I 2025-07-02 11:33:55,765] Trial 19 pruned. \n",
      "[I 2025-07-02 11:35:50,268] Trial 20 finished with value: 0.7050432935357094 and parameters: {'latent_dim': 78, 'dropout_rate': 0.17619367226941218, 'lr': 0.0004669520185657793, 'batch_size': 64, 'n_hidden_layers': 1, 'h_dim_0': 2421}. Best is trial 7 with value: 0.6441430374979973.\n",
      "[I 2025-07-02 11:35:52,366] Trial 21 pruned. \n",
      "[I 2025-07-02 11:35:54,103] Trial 22 pruned. \n",
      "[I 2025-07-02 11:35:55,266] Trial 23 pruned. \n",
      "[I 2025-07-02 11:36:46,032] Trial 24 finished with value: 0.6607261300086975 and parameters: {'latent_dim': 160, 'dropout_rate': 0.2289927428111164, 'lr': 0.0005491543680340897, 'batch_size': 128, 'n_hidden_layers': 1, 'h_dim_0': 1746}. Best is trial 7 with value: 0.6441430374979973.\n",
      "[I 2025-07-02 11:36:49,331] Trial 25 pruned. \n",
      "[I 2025-07-02 11:37:21,086] Trial 26 pruned. \n",
      "[I 2025-07-02 11:38:31,176] Trial 27 finished with value: 0.6790987849235535 and parameters: {'latent_dim': 195, 'dropout_rate': 0.22182089980082406, 'lr': 0.0005727542595780679, 'batch_size': 128, 'n_hidden_layers': 1, 'h_dim_0': 2386}. Best is trial 7 with value: 0.6441430374979973.\n",
      "[I 2025-07-02 11:38:34,925] Trial 28 pruned. \n",
      "[I 2025-07-02 11:40:24,201] Trial 29 finished with value: 0.6507101058959961 and parameters: {'latent_dim': 216, 'dropout_rate': 0.29759429713297003, 'lr': 0.00029596005491931585, 'batch_size': 64, 'n_hidden_layers': 1, 'h_dim_0': 2233}. Best is trial 7 with value: 0.6441430374979973.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization finished.\n",
      "Best trial:\n",
      "  Value: 0.6441430374979973\n",
      "  Params: \n",
      "    latent_dim: 146\n",
      "    dropout_rate: 0.2590700565837698\n",
      "    lr: 0.0002251207702163308\n",
      "    batch_size: 64\n",
      "    n_hidden_layers: 1\n",
      "    h_dim_0: 1424\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "\n",
    "print(\"Starting Optuna optimization...\")\n",
    "# Run the optimization for a number of trials\n",
    "# Adjust n_trials based on available time and computational resources\n",
    "study.optimize(lambda trial: objective(trial, optuna_parameters, input_dim, loader_workers), n_trials=30)\n",
    "print(\"\\nOptimization finished.\")\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1acba0b-e7e0-4dd6-857b-2f65f9471be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=7, state=TrialState.COMPLETE, values=[0.6441430374979973], datetime_start=datetime.datetime(2025, 7, 2, 11, 30, 19, 352509), datetime_complete=datetime.datetime(2025, 7, 2, 11, 31, 20, 631825), params={'latent_dim': 146, 'dropout_rate': 0.2590700565837698, 'lr': 0.0002251207702163308, 'batch_size': 64, 'n_hidden_layers': 1, 'h_dim_0': 1424}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.7883007153868675, 1: 0.7474474608898163, 2: 0.7233505994081497, 3: 0.7049784362316132, 4: 0.6917879655957222, 5: 0.6809936910867691, 6: 0.6736280769109726, 7: 0.6675284057855606, 8: 0.6629672721028328, 9: 0.658944770693779, 10: 0.6559156179428101, 11: 0.652863010764122, 12: 0.6508064121007919, 13: 0.6500130370259285, 14: 0.647303007543087, 15: 0.6477040722966194, 16: 0.6464295759797096, 17: 0.6459380313754082, 18: 0.6444969326257706, 19: 0.6441430374979973}, distributions={'latent_dim': IntDistribution(high=256, log=False, low=16, step=1), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.0, step=None), 'lr': FloatDistribution(high=0.001, log=False, low=1e-05, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128, 256)), 'n_hidden_layers': IntDistribution(high=3, log=False, low=1, step=1), 'h_dim_0': IntDistribution(high=4000, log=False, low=219, step=1)}, trial_id=7, value=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e757c-5fa1-4ee5-8859-71db48db6aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1534c0-3642-4985-8c68-1f6df30942a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
