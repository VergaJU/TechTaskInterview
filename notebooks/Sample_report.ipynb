{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08fea4d-baaa-438b-a57a-9d15438a9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gseapy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown,display, Image, SVG\n",
    "import io \n",
    "import shap\n",
    "import shap.maskers as maskers \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5722544-48b7-47e7-ba55-febc77489eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = os.path.dirname(os.path.abspath(''))\n",
    "sys.path.append(notebook_dir)\n",
    "from AE.AE import Autoencoder\n",
    "from AE.AEclassifier import AEClassifier, ClassificationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89870b0f-2637-4e0e-9aa4-8341d38af597",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load parameters\n",
    "# Autoencoder params:\n",
    "with open('/app/chatbot/test_params.yaml', \"r\") as f:\n",
    "    best_params=yaml.safe_load(f)\n",
    "# Classifier params\n",
    "with open('/app/chatbot/classifier_params.yaml', \"r\") as f:\n",
    "    classifier_params=yaml.safe_load(f)\n",
    "\n",
    "# load lables\n",
    "with open('/app/chatbot/Data/training_classifier_data.pkl','rb') as f:\n",
    "    data=pickle.load(f)\n",
    "    labels=data['labels_names']\n",
    "    num_classes=data['num_classes']\n",
    "    del data\n",
    "    \n",
    "# load gene names\n",
    "with open('/app/chatbot/Data/training_data.pkl', 'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "    genes=data['genes']\n",
    "    full_data=data['full_dataset']\n",
    "    del data\n",
    "\n",
    "with open('/app/chatbot/models/standard_scaler.pkl','rb') as f:\n",
    "    ss=pickle.load(f)\n",
    "\n",
    "with open('/app/chatbot/models/SHAP.pkl', 'rb') as f:\n",
    "    explainer=pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d3ff67-6650-4058-9de3-c810513ecc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate model\n",
    "\n",
    "# Extract hidden dimensions based on the suggested params\n",
    "best_hidden_dims = []\n",
    "n_hidden_layers = best_params['n_hidden_layers']\n",
    "for i in range(n_hidden_layers):\n",
    "    # Append the hidden dimension for each layer\n",
    "    if f'h_dim_{i}' in best_params:\n",
    "        best_hidden_dims.append(best_params[f'h_dim_{i}'])\n",
    "\n",
    "\n",
    "best_latent_dim = best_params['latent_dim']\n",
    "best_dropout_rate=best_params['dropout_rate']\n",
    "input_dim=len(genes)\n",
    "# Extract hidden dimensions based on the suggested params\n",
    "classifier_hidden_dims = []\n",
    "n_hidden_layers = classifier_params['n_hidden_layers']\n",
    "for i in range(n_hidden_layers):\n",
    "    # Append the hidden dimension for each layer\n",
    "    if f'h_dim_{i}' in classifier_params:\n",
    "        classifier_hidden_dims.append(classifier_params[f'h_dim_{i}'])\n",
    "classifier_dropout_rate=classifier_params['dropout_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c9b112-b1fb-4fba-8345-7b41ba8c7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_arch = Autoencoder(input_dim,\n",
    "                      best_latent_dim,\n",
    "                      best_hidden_dims,\n",
    "                     best_dropout_rate)\n",
    "\n",
    "\n",
    "classifier_model = AEClassifier(AE_arch.encoder,num_classes=num_classes, \n",
    "                                        latent_dim=best_latent_dim,\n",
    "                                        hidden_dims=classifier_hidden_dims, \n",
    "                                        dropout_rate=classifier_dropout_rate).to(device)\n",
    "classifier_model.load_state_dict(torch.load('/app/chatbot/models/classifier_model.pth', map_location=device))\n",
    "classifier_model = nn.Sequential(\n",
    "    classifier_model,\n",
    "    nn.Softmax(dim=1)  # apply softmax across classes\n",
    ")\n",
    "\n",
    "classifier_model.eval()\n",
    "classifier_model.to(device)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c4697-e698-4494-a7c9-33f7c7b2a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model_predict_proba(samples_features):\n",
    "    # Ensure input is 2D (n_samples, n_features) even if only one sample\n",
    "    if samples_features.ndim == 1:\n",
    "        samples_features = samples_features.reshape(1, -1)\n",
    "\n",
    "\n",
    "    # Convert numpy arrays to tensors and move to device\n",
    "    # samples_tensor = torch.FloatTensor(samples_features).to(device)\n",
    "\n",
    "    classifier_model.eval() # Ensure eval mode\n",
    "\n",
    "    # Perform forward pass through the *full* loaded_classifier_model\n",
    "    with torch.no_grad(): # No gradients needed for inference\n",
    "        probabilities = classifier_model(samples_features)\n",
    "        # probabilities = torch.softmax(logits, dim=1) # Get probabilities\n",
    "\n",
    "    # Move probabilities back to CPU and convert to NumPy\n",
    "    return probabilities\n",
    "\n",
    "def get_random_sample(genes,ss):\n",
    "    adata=sc.read('/app/chatbot/Data/dataset_annotated.h5ad')\n",
    "    samples=adata.obs_names\n",
    "    sample_name = random.choice(samples)\n",
    "    sample_gt=sc.get.obs_df(adata, keys='classification').loc[sample_name].values[0]\n",
    "    sample = sc.get.var_df(adata, keys=sample_name)\n",
    "    sample = sample[sample.index.isin(genes)].reindex(genes).T\n",
    "    return sample, sample_gt, sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71113fbe-2224-4940-a302-fa453ffdd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clinical_data\n",
    "except NameError:\n",
    "    clinical_data = {\n",
    "            \"age\": 50,\n",
    "            \"tumor_size\": 5,\n",
    "            \"lymph_node\": 'Positive',\n",
    "            \"er_status\": 'Positive',\n",
    "            \"pgr_status\": 'Negative',\n",
    "            \"her2_status\": 'Negative',\n",
    "            \"ki67_status\": 'NA',\n",
    "            \"nhg\": 'G2',\n",
    "            \"pam50\": 'NA'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25614948-4636-4feb-8d16-a422eac65b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_table=pd.DataFrame.from_dict({k:v for k,v in clinical_data.items() if v!='NA'},orient='index', columns=['Clinical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ddf15d-e970-4290-ba05-74941f43ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(f\"\"\"\n",
    "# Clinical Features:\n",
    "\n",
    "{clinical_table.to_html()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e93b0-0016-44fe-85a2-44c8d356e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sample\n",
    "    sample=pd.read_csv(sample)[['gene_id', 'expression']]\n",
    "    sample=sample.set_index('gene_id')\n",
    "    sample=ss.transform(sample.T[genes])\n",
    "except NameError:\n",
    "    sample, _, _ = get_random_sample(genes,ss)\n",
    "    sample = ss.transform(sample)\n",
    "sample = torch.Tensor(sample).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ca312-d33c-497b-bf54-bd4b1dfb5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = full_model_predict_proba(sample)\n",
    "cluster_id=np.argmax(probabilities.cpu().numpy()[0])\n",
    "cluster_name=labels[cluster_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f8442-ce4b-46e8-aa18-9e60866e3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(f\"\"\"\n",
    "# Predicted Cluster:\n",
    "\n",
    "{cluster_name}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d10f3-6e8c-4732-b200-5212eb5a8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_samples = sc.read('/app/chatbot/Data/dataset_annotated.h5ad').obs['classification']\n",
    "background_data=full_data.sample(1000, random_state=42,axis=0)\n",
    "background_features=torch.Tensor(background_data.to_numpy()).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502b6fe-d513-4498-9fe6-ea6c0140ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_mask = cluster_samples[cluster_samples=='Basal-G3'].index\n",
    "cluster_data = full_data[full_data.index.isin(cluster_mask)]\n",
    "cluster_features=torch.Tensor(cluster_data.to_numpy()).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3bdee0-a6fd-4fa9-8de6-52e6e578929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(sample)#, max_evals=20001, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d8523-506b-40d4-a680-8d36f5d44624",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class_id=labels.index(cluster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14aca51-c00f-41f3-8af9-fdeb0829c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class 2 SHAP values for sample 0\n",
    "vals = shap_values[0,:,cluster_id]\n",
    "base = explainer.expected_value[cluster_id]  # scalar\n",
    "Markdown(f\"\"\"\n",
    "# SHAP Values for cluster {cluster_name}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33399ef-ff74-4b46-ba13-31730b4662c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Explanation object\n",
    "explanation = shap.Explanation(\n",
    "    values=vals,\n",
    "    base_values=base,\n",
    "    data=sample.cpu().numpy()[0],  # the input features\n",
    "    feature_names=genes  # optional\n",
    ")\n",
    "\n",
    "# Plot\n",
    "ax = shap.plots.waterfall(explanation, show=False)\n",
    "fig = ax.figure\n",
    "buf = io.BytesIO()\n",
    "fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "buf.seek(0)\n",
    "display(Image(data=buf.read(), format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f4024-2c82-4fe4-9868-1e6fb95eb961",
   "metadata": {},
   "outputs": [],
   "source": [
    "shaps = pd.DataFrame({'gene_name':genes, 'score':vals}).sort_values('score',ascending=False)\n",
    "\n",
    "Markdown(f\"\"\"\n",
    "## Top 10 SHAP values with higher value:\n",
    "\n",
    "{shaps.sort_values(by='score',ascending=False).head(10).to_html()}\n",
    "\n",
    "## Top 10 SHAP values with lowest value:\n",
    "\n",
    "{shaps.sort_values(by='score',ascending=True).head(10).to_html()}\n",
    "\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d3edb-7ddc-449c-ba35-589d1fe070ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gseapy import Msigdb\n",
    "from gseapy import GSEA\n",
    "from gseapy import dotplot\n",
    "import gseapy as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8c168-345d-46bc-99d1-20556edbb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "msig = Msigdb()\n",
    "gmt = msig.get_gmt(category='h.all', dbver=\"2025.1.Hs\")\n",
    "\n",
    "\n",
    "def pathways(expr,ax):\n",
    "    pre_res = gp.prerank(\n",
    "        rnk=expr,  # DataFrame or path to .rnk file\n",
    "        gene_sets=gmt, \n",
    "        permutation_num=10000,  # recommended ≥1000\n",
    "        seed=42,\n",
    "        threads=4,  # parallelization\n",
    "        outdir=None\n",
    "    )\n",
    "    try:\n",
    "        ax = dotplot(pre_res.res2d,\n",
    "                 column=\"FDR q-val\",\n",
    "                 cmap=plt.cm.viridis,\n",
    "                 size=5, # adjust dot size\n",
    "                 show_ring=False,ax=ax, figsize=(10,15))\n",
    "    except:\n",
    "        ax=None\n",
    "    return ax, pre_res.res2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4f11c-bfbe-4be0-aec3-33791eb09409",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(f\"\"\"\n",
    "# GSEA:\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "ax, res = pathways(shaps,ax)\n",
    "fig = ax.figure\n",
    "buf = io.BytesIO()\n",
    "fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "buf.seek(0)\n",
    "display(Image(data=buf.read(), format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291e86e-dc99-4ef5-8780-7679fb0235db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ax is None:\n",
    "    res=res.iloc[:,:-1].sort_values(by='FDR q-val').head(20)\n",
    "    print(\"No significant enriched pathways\")\n",
    "else:\n",
    "    res=res.iloc[:,:-1].sort_values(by='FDR q-val')\n",
    "    res=res[res['FDR q-val']<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eae03a-09d7-43ac-854d-f4ce2e398824",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(f\"\"\"\n",
    "\n",
    "{res.to_html()}\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
